---
title: "Anomaly Detection with Domain Adaptation(CVPR2023)"
date: "2025-06-15"
tags: ['anomaly detection', 'domain adaptation', 'semi-supervised', 'IRAD']
draft: false
summary: "Invariant Representation Anomaly Detection(IRAD)을 통한 limited target 데이터 환경에서 anomaly detection을 진행하는 논문 리뷰"
---

# Anomaly Detection with Domain Adaptation

Semi-supervised anomaly detection 문제는 target 도메인에서 라벨링된 데이터가 제한적인 상황에서 정상과 비정상 데이터를 분류해야 한다는 점에서 어려움이 크다.  
특히, source 도메인에서는 정상(normal) 데이터만 사용할 수 있고, target 도메인에서도 일부 정상 데이터만 활용 가능한 상황에서 anomaly를 탐지해야 한다는 점에서, domain adaptation 기반의 접근이 필요하다.

이러한 문제 설정 하에서 본 논문은 **IRAD(Invariant Representation Anomaly Detection)** 구조를 제안하며, shared encoder와 private encoder를 결합한 adversarial training 구조를 통해 feature를 나누고자 하였다.

---

# Overall Method

![method.png](/static/images/anomaly-detection-da/method.png)

이 구조는 다른 semi-supervised 방식과 동일하게 feature extraction 과정 중 domain adaptation을 결합하여 target 도메인의 anomaly detection 성능을 향상시키는 것이 목표.  
Source data는 ImageNet으로 pre-trained된 ResNet-50을 통해 feature를 추출하며, normal 데이터만 사용된다.  

Target 도메인은 normal, abnormal 데이터를 모두 포함하되, 학습 시에는 normal 데이터만 활용하며, 이 역시 ResNet 기반 shared encoder를 통해 feature를 추출하게 된다.  
이러한 shared feature와 source domain 에 특징된 feature를 함께 활용하여 generator를 통해서 target-like 이미지를 생성하고, 이를 통해 최종적으로 anomaly detection을 수행한다.

Discriminator는 사전학습되지 않은 ResNet-18을 기반으로 이루어져 있다.

---

# Problem Statements

본 논문이 다루는 문제는 다음과 같다:

- **Settings**: source 도메인과 제한된 target 도메인 데이터가 주어짐
- **Limitations**: 학습 시에는 source와 target의 normal data만 사용 가능함
- **Test Env**: test set은 normal과 abnormal이 혼합됨
- **Metric**: AUROC을 사용하여 anomaly detection 성능을 평가함

---

# Method
## Shared + Private Encoder

기존의 domain adaptation 연구에서는 도메인이 달라져도 변하지 않는 **공통된 feature (domain-invariant feature)** 를 추출하는 방식이 일반적이다.  
IRAD는 이러한 기존 방식에 기반을 두면서도, **공통 feature와 domain-specific feature를 명확히 분리**하는 데 중점을 둔다.

이를 위해 shared encoder와 더불어 **private encoder**를 도입하였으며, 특히 source 도메인에 대해 특정된 정보를 뽑아내기 위해 adversarial training 구조를 사용하였다.

---

## Adversarial Loss

Generator에서는 다음과 같은 방식으로 학습이 진행된다:

1. **공통 feature + source-specific feature (from source)** → 하나의 이미지 생성
2. **공통 feature (from target) + source-specific feature** → 또 하나의 이미지 생성  
   이 둘은 discriminator를 통해 **같은 이미지**처럼 보이도록 유도된다.
3. **random vector + shared feature (from source)** → 추가로 하나 생성하여, private encoder가 과도하게 영향력을 갖지 않도록 제어한다.

Discriminator는 이 세 가지 이미지와 실제 source 이미지를 구분하도록 학습되며, 이 과정을 통해 **target domain에 align된 feature 공간을 구축**할 수 있게 된다.

![loss.png](/static/images/anomaly-detection-da/loss.png)

Adversarial Loss는 생성된 이미지가 진짜 source 이미지처럼 보이도록 학습하는 데 핵심적인 역할을 한다. GAN의 기본 아이디어에 기반하여, Generator는 Discriminator를 속이도록 학습되고, Discriminator는 진짜와 가짜 이미지를 구분하는 역할을 한다.

다음은 IRAD 논문에서 정의된 adversarial loss 함수이다:


```math
\min_{E_{sh}, E_{pv}, G_{src}} \max_{D_{src}} V(D_{src}, G_{src}, E_{pv}, E_{sh}) = 
\mathbb{E}_{x_{src}}[\log D_{src}(x_{src})] + \mathbb{E}_{x_{src}}[\log(1 - D_{src}(x'_{src}))] 
+ \mathbb{E}_{x_{src}, x_{tgt}}[\log(1 - D_{src}(x'_{tgt}))] + \mathbb{E}_{x_{src}}[\log(1 - D_{src}(x_{rnd}))]
```

`x'_{src}`는 source에서 생성된 복원 이미지이다.

`x'_{tgt}`는 source의 private feature와 target의 shared feature로부터 생성된 이미지이다.

`x_{rnd}`는 무작위 z와 source shared feature로부터 생성된 이미지이다.

이러한 다양한 조합의 생성 이미지를 통해 Discriminator는 더 강력하게 훈련되고, Generator와 Encoder는 더 정밀한 생성 결과를 출력할 수 있도록 학습된다.

Adversarial Loss는 모델이 보다 실제와 유사한 이미지를 생성하게 만들며, anomaly detection의 신뢰도를 높이는 데 기여한다.


---

## Cycle Consistency Loss

Cycle Consistency는 생성된 이미지가 원래 입력을 재현할 수 있도록 보장해준다. 이는 모델이 실질적인 변환만을 수행하고, 의미 있는 feature 공간을 학습하게 만드는 데 도움이 된다.

Source에서 생성된 `x'_{src}`는 다시 encoder에 통과되어 original `x_{src}`와의 유사도를 유지하도록 학습된다.

마찬가지로, `x'_{tgt}` 역시 target 스타일을 유지하면서도 source 기반의 생성 결과가 되도록 설계된다.

Cycle consistency loss는 다음과 같이 표현된다:


```math
l_{cyc} = \mathbb{E}_{x_{src}} [ \| x_{src} - G(E_{pv}(x_{src}) + E_{sh}(x_{src})) \|^2 ] + \mathbb{E}_{x_{tgt}} [ \| x_{tgt} - G(E_{pv}(x_{src}) + E_{sh}(x_{tgt})) \|^2 ]
```

이 손실은 기존 GAN 기반 모델들이 고차원에서 발생하는 mode collapse 또는 reconstruction fail case를 완화하는 데 중요한 역할을 한다.

---

# Additional Loss - Disentanglement Loss, Similarity Loss

shared encoder와 private encoder가 **서로 다른 특징**을 추출해야 하기 때문에, 각 encoder의 역할을 명확히 분리하는 목적의 추가적인 loss term을 도입하였다.
Disentanglement Loss는 공통 feature와 private feature의 내적을 최소화함으로써 서로 다른 정보만을 담도록 학습된다.

###  Disentanglement Loss

```math
l_{dis} = ||E_{sh}(x_{src})^T E_{pv}(x_{src})||
```

### Similarity Loss

Similarity Loss는 Source와 target의 shared feature가 유사한 방향을 갖도록 유도하기 위해 두 벡터의 내적을 최대화하는 방향으로 학습된다. 이는 target 데이터가 적은 상황에서도 공통 feature space를 효과적으로 구축하기 위한 핵심 요소이다.

```math
l_{sim} = - \left\| E_{sh}(x_{src})^T E_{sh}(x_{tgt}) \right\|
```

---

더 자세한 내용은, 본 논문을 참고하면 된다 !:  
[📄 Read the paper on arXiv](https://openaccess.thecvf.com/content/CVPR2023W/VAND/papers/Yang_Anomaly_Detection_With_Domain_Adaptation_CVPRW_2023_paper.pdf)