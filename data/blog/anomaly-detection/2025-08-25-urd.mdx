---
title: "Unlocking the Potential of Reverse Distillation for Anomaly Detection(AAAI2025)"
date: "2025-08-25"
tags: ['anomaly detection', 'RevsedDistillation', 'RD', 'URD', 'KnowledgeDistillation']
draft: false
summary: "Reverse Distillation ë°©ì‹ì„ í™œìš© ë° ê°œì„ í•˜ì—¬ anomaly detection ì„±ëŠ¥ì„ ë†’ì¸ URD ë…¼ë¬¸ ë¦¬ë·°"
---

# Unlocking the Potential of Reverse Distillation for Anomaly Detection

RD(Reverse distillation)ëŠ” KD(Knowledge Distillation)ì—ì„œ student ì˜ êµ¬ì¡°ë¥¼ ì¸ì½”ë”ì—ì„œ ë””ì½”ë”ë¡œ ë³€í˜•í•˜ì—¬ Anomaly Detection(AD)ì—ì„œ ì‚¬ìš©ë˜ê³  ìˆë‹¤. ì´ ë°©ë²•ì„ ì œì•ˆí•œ anomaly detection ê³¼ì •ì—ì„œëŠ” ì‚¬ì „ í•™ìŠµëœ teacher encoder **E**, one-class bottleneck embedding(OCBE) ëª¨ë“ˆ, ê·¸ë¦¬ê³  student decoder **D**ë¡œ êµ¬ì„±ëœë‹¤. í•™ìŠµ ê³¼ì •ì—ì„œëŠ” ì •ìƒ(normal) ì´ë¯¸ì§€ë§Œì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. OCBE ëª¨ë“ˆì€ ë©€í‹° ìŠ¤ì¼€ì¼ íŒ¨í„´ì„ ì €ì°¨ì› ì„ë² ë”© ê³µê°„ìœ¼ë¡œ ì••ì¶•í•˜ë©°, ì´ ì„ë² ë”©ì„ studentì— ì „ë‹¬í•˜ì—¬ teacher featureë¥¼ ë³µì›í•˜ê²Œ ëœë‹¤. inference ê³¼ì •ì—ì„œ teacherëŠ” ì •ìƒ ë¶„í¬ì—ì„œ ë²—ì–´ë‚˜ëŠ” ì´ìƒ íŠ¹ì§•(anomalous features)ì„ í¬ì°©í•  ìˆ˜ ìˆê³ , OCBEëŠ” ì´ëŸ¬í•œ ì´ìƒ ì •ë³´ê°€ ê·¸ëŒ€ë¡œ studentì— ì…ë ¥ë˜ëŠ” ê²ƒì„ ë§‰ì•„ì¤€ë‹¤. ë”°ë¼ì„œ studentëŠ” ì •ìƒ ì´ë¯¸ì§€ë¿ ì•„ë‹ˆë¼ ì´ìƒ ì´ë¯¸ì§€ê°€ ì…ë ¥ë˜ë”ë¼ë„ anomaly-free featureë¥¼ ìƒì„±í•˜ë„ë¡ ìœ ë„ëœë‹¤. ê·¸ë ‡ê²Œ ë˜ë©´ teacherì˜ í”¼ì²˜ì™€ studentì˜ feature ê°„ì˜ ì°¨ì´ê°€ ì»¤ì§€ê²Œ ë˜ë©°, ì´ë¥¼ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°í•˜ì—¬ anomaly detection ì„ ì§„í–‰í•˜ëŠ” ë°©ì‹ì´ë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ RDë°©ì‹ì— ëŒ€í•œ ë¬¸ì œì ì„ ì œì‹œí•˜ëŠ”ë°, 

### 1. Miss Detection ë¬¸ì œ

RDëŠ” ë‘ ê°€ì§€ í•µì‹¬ ì „ì œë¥¼ ì§€ë‹ˆê³  ìˆëŠ”ë°, ì²«ì§¸, teacherëŠ” ì´ìƒ ì˜ì—­ì—ì„œ ì •ìƒ featureì™€ êµ¬ë³„ë˜ëŠ” ë¹„ì •ìƒ featureë¥¼ ìƒì„±í•´ì•¼ í•œë‹¤. ê·¸ëŸ¬ë‚˜ ì‹¤ì œ ìƒí™©ì—ì„œëŠ” ì´ìƒ ì˜ì—­ì´ ë§¤ìš° ì‘ê±°ë‚˜ receptive field ë‚´ì— ì •ìƒ í”½ì…€ì´ ëŒ€ë¶€ë¶„ì¼ ê²½ìš° teacherê°€ ì´ìƒì„ ì œëŒ€ë¡œ í¬ì°©í•˜ì§€ ëª»í•  ìˆ˜ ìˆë‹¤. ë‘˜ì§¸, studentëŠ” anomaly-free featureë¡œë§Œ reconstructí•œë‹¤ëŠ” ê°€ì •ì¸ë°, RDì—ì„œ OCBEëŠ” ë‹¨ìˆœ downsamplingì„ ìˆ˜í–‰í•˜ê¸° ë•Œë¬¸ì— ì—¬ì „íˆ ë¹„ì •ìƒ í”¼ì²˜ê°€ student ì…ë ¥ì— í¬í•¨ë˜ì–´ anomaly í•œ ì˜ì—­ìœ¼ë¡œ reconstructë  ìˆ˜ ìˆë‹¤. ë˜í•œ student decoderëŠ” ë‹¤ì¸µ convolution êµ¬ì¡°ë¡œ ì¼ë°˜í™” ëŠ¥ë ¥ì´ ê°•í•˜ê¸° ë•Œë¬¸ì— ì •ìƒ ë°ì´í„°ë§Œìœ¼ë¡œ í•™ìŠµë˜ë”ë¼ë„ teacherì™€ ìœ ì‚¬í•œ ì´ìƒ featureë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ ì´ìœ ë¡œ teacherì™€ student feature ê°„ ì°¨ì´ê°€ ì¶©ë¶„íˆ ë°œìƒí•˜ì§€ ì•Šì•„ ì¼ë¶€ ì´ìƒ ì˜ì—­ì´ íƒì§€ë˜ì§€ ëª»í•˜ëŠ” miss detection ë¬¸ì œê°€ ë‚˜íƒ€ë‚œë‹¤.

### 2. False Positive ë¬¸ì œ

teacher encoderëŠ” ì—¬ëŸ¬ ë‹¨ê³„ì˜ downsamplingê³¼ convolutionì„ ì§€ë‚˜ê°€ê¸° ë•Œë¬¸ì—, ìµœì¢… high-level featureëŠ” low-level feature ëŒ€ë¹„ ë§ì€ ë””í…Œì¼í•œ ì •ë³´ê°€ ì†ì‹¤ëœë‹¤. ì´ ìƒíƒœì—ì„œ high-level featureë§Œì„ ê¸°ë°˜ìœ¼ë¡œ reconstructionì„ ì§„í–‰í•˜ë©´ **ì •ìƒ ì˜ì—­ì—ì„œë„ reconstruction errorê°€ í¬ê²Œ ë°œìƒí•˜ì—¬ false positiveê°€ ì¦ê°€**í•œë‹¤. ì „í†µì ì¸ reconstruction ë„¤íŠ¸ì›Œí¬ì—ì„œëŠ” ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ skip connectionì„ í™œìš©í•˜ì—¬ encoder featureë¥¼ decoderì— ì§ì ‘ ì „ë‹¬í•œë‹¤. ê·¸ëŸ¬ë‚˜ RDì—ì„œ ì´ëŸ¬í•œ ë°©ì‹ì€ teacher encoderì˜ ë¹„ì •ìƒ featureê°€ student decoderë¡œ ì „ë‹¬ë  ìœ„í—˜ì´ ìˆì–´ anomaly-free feature ìƒì„±ì„ ë°©í•´í•  ìˆ˜ ìˆë‹¤. 

RDëŠ” ì´ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ Multi-level Feature Fusion(MFF) êµ¬ì¡°ë¥¼ ì œì•ˆí•˜ì—¬ ì—¬ëŸ¬ ë‹¨ê³„ì˜ encoder featureë¥¼ í†µí•©í•´ decoder ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. í•˜ì§€ë§Œ ì´ ê³¼ì •ì—ì„œ featureë“¤ì´ ë‹¤ì‹œ downsamplingë˜ì–´ ì„¸ë¶€ ì •ë³´ê°€ ìƒë‹¹ ë¶€ë¶„ ì†ì‹¤ë˜ëŠ” ë¬¸ì œì ì„ ì§€ë‹Œë‹¤. ê²°êµ­ ì •ìƒ ì˜ì—­ì—ì„œë„ teacherì™€ student feature ê°„ ì°¨ì´ê°€ í¬ê²Œ ë°œìƒí•˜ê³ , ì´ëŠ” anomaly detectionì—ì„œ ì„±ëŠ¥ ì €í•˜ë¥¼ ì¼ìœ¼í‚¤ëŠ” false positiveë¡œ ì´ì–´ì§€ê²Œ ëœë‹¤.

ì¦‰, RDëŠ” teacherì™€ student ê°„ì˜ feature ì°¨ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ anomalyë¥¼ íƒì§€í•˜ëŠ” êµ¬ì¡°ì´ì§€ë§Œ, teacherê°€ **anomalyë¥¼ ì¶©ë¶„íˆ í¬ì°©í•˜ì§€ ëª»í•˜ê±°ë‚˜ studentê°€ anomaly-free feature ìƒì„±ì„ ë³´ì¥í•˜ì§€ ëª»í•˜ëŠ” ìƒí™©**ì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ë˜í•œ MFF ê¸°ë°˜ êµ¬ì¡°ëŠ” ì •ìƒ ì˜ì—­ì—ì„œë„ reconstruction ì°¨ì´ë¥¼ ìœ ë°œí•˜ì—¬ false positiveë¥¼ ì¦ê°€ì‹œí‚¤ëŠ” í•œê³„ë¥¼ ê°€ì§„ë‹¤. ë”°ë¼ì„œ RD ê¸°ë°˜ anomaly detectionì€ miss detectionê³¼ false positive ëª¨ë‘ì— ì·¨ì•½í•˜ë©°, ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œëŠ” teacherì™€ studentì˜ feature ì „ë‹¬ ë° ì²˜ë¦¬ ê³¼ì •ì„ ì •êµí•˜ê²Œ ì„¤ê³„í•˜ëŠ” ë³´ì™„ ëª¨ë“ˆì´ í•„ìš”í•˜ê²Œ ë¨ì„ ì§€ì í•˜ê³  ìˆë‹¤.

![overallmethod.png](/static/images/urd/overallmethod.png)

ìœ„ì˜ ì´ë¯¸ì§€ì™€ ê°™ì´ RD++ ë°©ì‹ìœ¼ë¡œ anomaly imageë¥¼ ë§Œë“¤ì–´ì„œ bottleneck êµ¬ì¡°ì—ì„œ student networkê°€ anomaly-freeí•œ featureë§Œ reconstructë  ìˆ˜ ìˆë„ë¡ denoising ë°©ì‹ì„ ì¶”ê°€í•˜ê±°ë‚˜, (c) ë°©ì‹ì²˜ëŸ¼ template guidedë¼ í•˜ì—¬ memory bankì— ì¢‹ì€ normal featureë“¤ì„ ì €ì¥í•˜ëŠ” ë°©ì‹ì´ ìˆì§€ë§Œ (b) ê°™ì€ ê²½ìš°ëŠ” normal pixelì´ ê·¹ì†ŒëŸ‰ì´ê±°ë‚˜ receptive fieldì— normalí•œ ì •ë³´ê°€ ëŒ€ë¶€ë¶„ì¼ ê²½ìš°ì—ëŠ” abnormalí•œ ì˜ì—­ì— ëŒ€í•´ normalí•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆë‹¤ëŠ” ê°€ì •ì´ ê¹¨ì ¸ë²„ë¦´ ìˆ˜ ìˆê²Œ ë˜ë©°, (c) ê°™ì€ ê²½ìš°ì—ëŠ” ë©”ëª¨ë¦¬ ì†Œìš”, ì—°ì‚°ëŸ‰ì´ ëŠ˜ì–´ë‚˜ê²Œëœë‹¤.

# Proposed Method

## Expert-Teacher-Student (E-T-S) Network

![method.png](/static/images/urd/method.png)

ìœ„ì˜ ì•„í‚¤í…ì²˜ ê·¸ë¦¼ê³¼ ê°™ì´, ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” ì „ì²´ ì•„í‚¤í…ì²˜ëŠ” RDì˜ teacher-student frameworkë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ **Expert-Teacher-Student (E-T-S) Network**ë¡œ í™•ì¥í•˜ì˜€ë‹¤. ì´ êµ¬ì¡°ëŠ” RDì˜ teacher, bottleneck, student ëª¨ë“ˆì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë©´ì„œë„ ì¶”ê°€ì ì¸ expertë¥¼ ë„ì…í•œ êµ¬ì¡°ë¥¼ ì§€ë‹Œë‹¤.

ê°ê° íŠ¹ì§•ì— ëŒ€í•´ ì •ë¦¬í•´ë³´ë©´

- **Teacher Encoder (T)**ëŠ” ImageNetìœ¼ë¡œ ì‚¬ì „ í•™ìŠµëœ WideResNet-50ì„ ì‚¬ìš©í•œë‹¤.
- **Bottleneck**ì€ RDì—ì„œ ì œì•ˆëœ One-Class Bottleneck Embedding (OCBE)ì„ ë™ì¼í•˜ê²Œ ì‚¬ìš©í•˜ë©°,  **Multi-scale Feature Fusion(MFF)** ëª¨ë“ˆê³¼ **One-Class Embedding (OCE)** ëª¨ë“ˆë¡œ êµ¬ì„±ëœë‹¤.
- **Student Decoder (S)**ëŠ” teacherì™€ ëŒ€ì¹­ì ì¸ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ë¥¼ ê°€ì§€ë©°, downsampling ëŒ€ì‹  upsampling ì—°ì‚°ì„ ìˆ˜í–‰í•œë‹¤. (ì¦‰ ë””ì½”ë” ì—­í• ) ë˜í•œ student ë‚´ë¶€ì—ëŠ” encoder ì •ë³´ë¥¼ ì£¼ì…í•˜ê¸° ìœ„í•œ **Guided Information Injection (GII)** ëª¨ë“ˆì„ í¬í•¨í•œë‹¤.
- URDì—ì„œëŠ” **Expert Network (E)**ë¥¼ ìƒˆë¡­ê²Œ ë„ì…í•˜ì˜€ëŠ”ë°, ExpertëŠ” teacherì™€ ë™ì¼í•œ êµ¬ì¡° ë° ì´ˆê¸° íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§€ë©°, ì •ìƒ(normal) ë°ì´í„°ë§Œìœ¼ë¡œ í•™ìŠµëœë‹¤.

í•™ìŠµ ê³¼ì •ì—ì„œ RDì™€ ë‹¬ë¦¬ teacher, bottleneck, student ëª¨ë‘ trainableì´ë©°, teacherëŠ” ë…ë¦½ì ì¸ optimizerë¥¼ ì‚¬ìš©í•˜ê³ , bottleneckê³¼ studentëŠ” ë™ì¼í•œ optimizerë¥¼ ê³µìœ í•œë‹¤. inference ë•ŒëŠ” í•™ìŠµì´ ì™„ë£Œëœ teacherì™€ studentë¥¼ ê³ ì •(frozen)í•˜ì—¬ anomaly detectionê³¼ localizationì— ì‚¬ìš©í•œë‹¤.

---

## Reverse Distillation with Expert

RDëŠ” teacherê°€ anomalyë¥¼ ì¶©ë¶„íˆ ì¸ì‹í•  ìˆ˜ ìˆê³ , ë™ì‹œì— studentê°€ anomaly-free featureë¥¼ ìƒì„±í•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤ê³  ì „ì œí•˜ê³  ìˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ RD ëª¨ë¸ë“¤ì€ ì´ ë‘ ì¡°ê±´ì„ ë™ì‹œì— ë§Œì¡±í•˜ì§€ ëª»í•˜ì—¬ **miss detection ë¬¸ì œë¥¼ ì§€ë‹ˆê³  ìˆë‹¤**. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” expert networkë¥¼ ë„ì…í•˜ì—¬ teacherì™€ student **ëª¨ë‘ë¥¼ ë™ì‹œì— distillationí•˜ë„ë¡ ì„¤ê³„**í•˜ì˜€ë‹¤.

- TeacherëŠ” anomalyì— ë”ìš± ë¯¼ê°í•˜ë„ë¡ optimizeë˜ê³ , ì •ìƒê³¼ ë¹„ì •ìƒ featureë¥¼ ëª…í™•íˆ êµ¬ë¶„í•  ìˆ˜ ìˆë„ë¡ í•™ìŠµëœë‹¤.
- StudentëŠ” denoising ë°©ì‹ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©°, ì…ë ¥ì´ anomalous sampleì´ë”ë¼ë„ ì •ìƒ featureë¥¼ ì¬êµ¬ì„±í•˜ë„ë¡ í•™ìŠµëœë‹¤.

ì´ dual-strategy distillationì€ normal ì˜ì—­ì—ì„œëŠ” teacherì™€ student featureê°€ ìœ ì‚¬í•˜ë„ë¡ í•˜ê³ , anomalous ì˜ì—­ì—ì„œëŠ” ë¶ˆì¼ì¹˜í•˜ë„ë¡ ìœ ë„í•¨ìœ¼ë¡œì¨ anomaly detection ë° localization ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤.

---

## Anomaly Synthesis

í•™ìŠµ ì‹œ ê° ì •ìƒ ì´ë¯¸ì§€ $I^n$ì— ëŒ€í•´, ëŒ€ì‘ë˜ëŠ” í•©ì„± anomaly ì´ë¯¸ì§€ $I^a$ë¥¼ ìƒì„±í•œë‹¤. ì´ë•Œ anomaly í•©ì„±ì€ **DRÃ†M**(Zavrtanik et al., 2021)ì„ ë”°ë¼ Perlin noise generatorì™€ Describable Textures Datasetì„ ì‚¬ìš©í•´ì„œ anomaly imageë¥¼ ìƒì„±í•œë‹¤. (ì•„í‚¤í…ì²˜ì—ì„œ íŒŒë€ìƒ‰ ë™ê·¸ë¦¬ë¯¸ ë¶€ë¶„)

Teacher $T$ëŠ” ë‘ ì´ë¯¸ì§€ ìŒ $I={I^n, I^a}$ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì„¸ ë‹¨ê³„ì˜ featureë¥¼ ì¶œë ¥í•œë‹¤.

$F_T^n = \{F_{T1}^n, F_{T2}^n, F_{T3}^n\} = T(I^n),
\quad
F_T^a = \{F_{T1}^a, F_{T2}^a, F_{T3}^a\} = T(I^a)$

Student $S$ëŠ” teacherì˜ featureë¥¼ ì…ë ¥ë°›ì•„ ëŒ€ì‘ë˜ëŠ” featureë¥¼ ë³µì›í•œë‹¤.

$F_S^n = \{F_{S1}^n, F_{S2}^n, F_{S3}^n\} = S(F_T^n), 
\quad
F_S^a = \{F_{S1}^a, F_{S2}^a, F_{S3}^a\} = S(F_T^a)$

Expert $E$ëŠ” ì •ìƒ ì´ë¯¸ì§€ë§Œì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ë‹¤ìŒê³¼ ê°™ì€ featureë¥¼ ìƒì„±í•œë‹¤.

$F_E = \{F_{E1}^n, F_{E2}^n, F_{E3}^n\} = E(I^n)$

---

## Teacher Loss: Anomaly Sensitivity

Teacherì˜ anomaly ê°ì§€ ë¯¼ê°ë„ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´, ground truth anomaly mask $M_{gt}$ë¥¼ ì‚¬ìš©í•˜ì—¬ feature extraction ê³¼ì •ì„ ê°€ì´ë“œí•˜ëŠ” ì—­í• ì„ í•œë‹¤. ì •ìƒ ì˜ì—­ì—ì„œëŠ” cosine similarityë¥¼ ë†’ê²Œ ìœ ì§€í•˜ê³ (ë†’ì„ìˆ˜ë¡ ë¹„ìŠ·í•˜ë‹¤), anomaly ì˜ì—­ì—ì„œëŠ” teacherì˜ abnormal featureì™€ expertì˜ normal feature ê°„ cosine distanceë¥¼ ì¦ê°€(ì¦ê°€í• ìˆ˜ë¡ ë‹¤ë¥´ë‹¤)ì‹œí‚¨ë‹¤.

ê° ìœ„ì¹˜ $(h, w)$ì—ì„œ teacherì™€ expert ê°„ cosine distanceëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ëœë‹¤.

$D_{TE}^{n/a, i}(h, w) = 1 - \frac{F_{Ti}^{n/a}(h, w) \cdot F_{Ei}^n(h, w)}{\|F_{Ti}^{n/a}(h, w)\|\|F_{Ei}^n(h, w)\|}$

ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ teacherì˜ lossëŠ” L1 distance ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°ëœë‹¤.

$L_{TE}^{n/a} = \sum_{i=1}^3 \Bigg\{ \frac{1}{H_i W_i} \sum_{h=1}^{H_i} \sum_{w=1}^{W_i} \big| D_{TE}^{n/a, i}(h, w) - M_{gt}^i(h, w)\big| \Bigg\}$

ìµœì¢… teacher lossëŠ” ì •ìƒê³¼ ì´ìƒ ì˜ì—­ì— ëŒ€í•œ í•©ìœ¼ë¡œ ì •ì˜ëœë‹¤.

$L_{TE} = L_{TE}^n + L_{TE}^a$

ì—¬ê¸°ì„œ $H_i, W_i$ëŠ” ië²ˆì§¸ ë¸”ë¡ featureì˜ heightì™€ widthë¥¼ ì˜ë¯¸í•˜ë©°, $M_{gt}^i$ëŠ” feature í¬ê¸°ì— ë§ë„ë¡ downsamplingëœ anomaly maskì´ë‹¤.

ì •ìƒ ì˜ì—­(normal region)ì—ì„œëŠ” teacherì™€ expertê°€ ëª¨ë‘ ì •ìƒ featureë¥¼ ë³´ê³  ìˆìœ¼ë¯€ë¡œ,

- **teacherì˜ feature**ì™€ **expertì˜ feature**ëŠ” ë§¤ìš° ìœ ì‚¬í•´ì•¼ í•¨.
- ì¦‰, $\text{CosSim}(F_T^n, F_E^n)$ ê°’ì´ 1ì— ê°€ê¹ê²Œ ìœ ì§€ë˜ë„ë¡ í•™ìŠµí•´ì•¼ í•¨.

â†’ ì´ ë§ì€ **teacherë„ ì •ìƒ ì˜ì—­ì—ì„œëŠ” expertì™€ ê±°ì˜ ê°™ì€ í‘œí˜„ì„ ë‚´ë„ë¡ ìœ ë„í•œë‹¤**ëŠ” ì˜ë¯¸ !

ì´ìƒ ì˜ì—­(anomalous region)ì—ì„œëŠ” teacherê°€ anomalyì— ë¯¼ê°í•´ì•¼ í•¨.

- ExpertëŠ” normal imageë§Œìœ¼ë¡œ í•™ìŠµë˜ì—ˆìœ¼ë¯€ë¡œ anomalyë¥¼ ë³´ì§€ ëª»í•¨ â†’ anomalyê°€ ë“¤ì–´ì™€ë„ normal-like featureë§Œ ëƒ„.
- TeacherëŠ” anomalyë¥¼ êµ¬ë¶„í•´ì•¼ í•˜ë¯€ë¡œ, anomaly ì˜ì—­ì—ì„œëŠ” expertì˜ featureì™€ **ë‹¬ë¼ì ¸ì•¼ í•¨**.
- ë”°ë¼ì„œ $\text{CosDist}(F_T^a, F_E^n)$ê°€ ì»¤ì§€ë„ë¡, ì¦‰ $\text{CosSim}$ ê°’ì´ ë‚®ì•„ì§€ë„ë¡ í•™ìŠµí•´ì•¼ í•¨.

â†’ ì´ ë§ì€ **teacherê°€ anomalyë¥¼ ë³¼ ë•Œ expertì™€ ë‹¬ë¦¬ ë°˜ì‘í•˜ì—¬ feature ì°¨ì´ë¥¼ í¬ê²Œ ë§Œë“ ë‹¤**ëŠ” ì˜ë¯¸.

---

## Student Loss: Feature Denoising

StudentëŠ” teacherì™€ expertë¥¼ ë™ì‹œì— ì°¸ì¡°í•˜ì—¬ ì •ìƒ featureë¥¼ ì¬êµ¬ì„±í•˜ë„ë¡ í•™ìŠµëœë‹¤. ì¦‰, ì •ìƒ/ë¹„ì •ìƒ ì´ë¯¸ì§€ê°€ ì…ë ¥ë˜ë”ë¼ë„ í•­ìƒ ì •ìƒ featureë¥¼ ë³µì›í•˜ëŠ” ê²ƒì´ ëª©í‘œì´ë‹¤. ì´ë¥¼ ìœ„í•´ cosine similarity ê¸°ë°˜ì˜ lossë¥¼ ì„¤ê³„í•˜ì˜€ë‹¤.

ë¨¼ì € flatten ì—°ì‚° $F(\cdot)$ë¥¼ ì ìš©í•˜ì—¬ featureë¥¼ ë²¡í„°í™”í•œë‹¤. (ì—¬ê¸°ì„œ flatten ì—°ì‚°ì€ ReContrast ì—ì„œ ì œì•ˆëœ flatten operation ì´ë¼ê³  í•œë‹¤.)

### ì—¬ê¸°ì„œ ì™œ Flattenì„ Student loss ì—°ì‚°ì—ë§Œ ì§„í–‰í• ê¹Œ?

- ReContrastì—ì„œë„ ì´ì•¼ê¸°í–ˆì§€ë§Œ, Flattení•˜ë©´ ê° ì´ë¯¸ì§€ê°€ **í•˜ë‚˜ì˜ embedding vector**ë¡œ ê°„ì£¼ë˜ì–´, contrastive lossë‚˜ cosine similarity ê³„ì‚°ì´ ë” ê°„ë‹¨í•´ì§„ë‹¤.
- Student Lossë„ ê°™ì€ ë§¥ë½ì—ì„œ flatten featureë¥¼ ì‚¬ìš©í•´ **representation-level alignment**ë¥¼ ìœ ë„í•œë‹¤.
- **ì¦‰, H,W ë‹¨ìœ„**ë¡œ cosine similarityë¥¼ ê³„ì‚°í•˜ë©´ **local alignment (í”½ì…€/patch ìˆ˜ì¤€)**ì„ í•™ìŠµ â†’ anomaly localizationì— ì í•©í•˜ì§€ë§Œ,
- **Flatten í›„ ë²¡í„° ë‹¨ìœ„**ë¡œ cosine similarityë¥¼ ê³„ì‚°í•˜ë©´ **global alignment (ì „ì²´ representation ìˆ˜ì¤€)**ì„ í•™ìŠµ â†’ Studentê°€ í•­ìƒ ì •ìƒ featureë¥¼ ë³µì›í•˜ëŠ” **representation-level denoising**ì— ì í•©í•˜ë‹¤.

ì¦‰, student lossì—ì„œëŠ” **pixel-wise error**ê°€ ì•„ë‹ˆë¼ **ì „ì²´ feature ë°©í–¥ì„±**ì„ normalì— ë§ì¶”ëŠ” ê²Œ ì¤‘ìš”í•˜ê¸° ë•Œë¬¸ì— flattenì„ ì ìš©í•˜ëŠ” ê²ƒ !

$$f = F(F)$$

ì´í›„ student featureì™€ teacher/expert feature ê°„ cosine similarityë¥¼ ê¸°ë°˜ìœ¼ë¡œ lossë¥¼ ê³„ì‚°í•œë‹¤.

$$
L_{SE/ST}^i = \Big(1 - \frac{f_{Si}^n \cdot f_{E/T, i}^n}{\|f_{Si}^n\|\|f_{E/T, i}^n\|}\Big) + \Big(1 - \frac{f_{Si}^a \cdot f_{E/T, i}^n}{\|f_{Si}^a\|\|f_{E/T, i}^n\|}\Big)
$$

ìµœì¢… student lossëŠ” ëª¨ë“  layerì— ëŒ€í•´ í•©ì‚°ëœë‹¤.

$$L_S = \sum_{i=1}^3 (L_{SE}^i + L_{ST}^i)$$

## Guided Information Injection (GII)

![GII.png](/static/images/urd/GII.png)

**ë˜í•œ URDì—ì„œëŠ” ì¶”ê°€ì ìœ¼ë¡œ Guided Information Injection (GII)** ëª¨ë“ˆì„ ì œì•ˆí•œë‹¤. GIIëŠ” ìœ„ì— ì œì‹œëœ ë°”ì™€ ê°™ì´ teacher encoderì™€ student decoder ì‚¬ì´ì— ìœ„ì¹˜í•˜ë©°, encoderì—ì„œ ì¶”ì¶œëœ detail ì •ë³´ë¥¼ decoderë¡œ ë³´ë‹¤ ì •ì œëœ ë°©ì‹ìœ¼ë¡œ ì£¼ì…í•œë‹¤.

ì´ë¥¼ ì„¤ê³„í•œ ê·¼ê±°ëŠ” ë‹¤ìŒ ë‘ ê°€ì§€ ê´€ì°°ì—ì„œ ì¶œë°œí•œë‹¤. ì²«ì§¸, **higher-level featureëŠ” textureì™€ ê°™ì€ ì €ì°¨ì› ë””í…Œì¼ ì •ë³´ê°€ ì ê¸° ë•Œë¬¸ì—, ë””í…Œì¼í•œ reconstructionì— ëŒ€í•œ ì¤‘ìš”ì„±ì€ ë‚®ë‹¤.** ë‘˜ì§¸, **higher-level featureëŠ” decoderë¡œ ì „ë‹¬ë˜ëŠ” ê²½ë¡œê°€ ì§§ì•„ ìƒëŒ€ì ìœ¼ë¡œ recontruction qualityê°€ ìš°ìˆ˜í•˜ë‹¤.** ì´ëŸ¬í•œ ì´ìœ ë¡œ, ê·¸ë¦¼(a) ì—ì„œ í™•ì¸ëœ ê²ƒì²˜ëŸ¼ high-level featureì˜ cosine similarity ê¸°ë°˜ distance mapì€ anomaly localizationì— íš¨ê³¼ì ìœ¼ë¡œ í™œìš©ë  ìˆ˜ ìˆë‹¤.

ì´ëŸ¬í•œ ì‚¬ì‹¤ì„ ê¸°ë°˜ìœ¼ë¡œ ì œì•ˆí•œ GIIëŠ” high-level featureë¡œë¶€í„° similarity-based attentionì„ ê³„ì‚°í•˜ì—¬ encoder featureê°€ decoderë¡œ ì£¼ì…ë˜ëŠ” ë¹„ìœ¨ì„ ì¡°ì ˆí•œë‹¤. ì´ë¥¼ í†µí•´ reconstruction ê³¼ì •ì—ì„œ **(1) low-level detail ì •ë³´ ë¶€ì¡± ë¬¸ì œë¥¼ ë³´ì™„**í•˜ê³ , **(2) anomalous featureê°€ ê·¸ëŒ€ë¡œ leakage ë˜ëŠ” ë¬¸ì œë¥¼ ì–µì œ**í•  ìˆ˜ ìˆë‹¤. ì¦‰, ì „í†µì ì¸ skip connectionì´ ë¬´ë¶„ë³„í•˜ê²Œ low-level featureë¥¼ ì „ë‹¬í•˜ëŠ” ë°©ì‹ê³¼ ë‹¬ë¦¬, GIIëŠ” attention ê¸°ë°˜ filteringì„ í†µí•´ ì •ìƒ ì •ë³´ ìœ„ì£¼ì˜ detailì„ softí•˜ê²Œ ì£¼ì…í•œë‹¤.

---

### GII ëª¨ë“ˆ êµ¬ì¡°

GIIëŠ” student decoderì˜ ë‘ ë¸”ë¡ $S_1, S_2$ ì•ì— ì‚½ì…ëœë‹¤. $S_i$ ì•ì— ìœ„ì¹˜í•œ GIIì˜ ì…ë ¥ì€ teacher encoderì˜ ì¶œë ¥ feature $F_T^i$, $F_T^{i+1}$ê³¼ student decoderì˜ ìƒìœ„ ë¸”ë¡ ì¶œë ¥ feature $F_S^{i+1}$ë¡œ êµ¬ì„±ëœë‹¤.

ê³¼ì •ì„ í•˜ë‚˜í•˜ë‚˜ ì‚´í´ë³´ì.

1. **Multi-scale Feature Fusion**
    
    ë¨¼ì €, $F_T^i$ì™€ $F_T^{i+1}$ëŠ” ì±„ë„ ì°¨ì›ì„ ë§ì¶˜ ë’¤ ê²°í•©í•˜ì—¬ multi-scale fused featureë¥¼ ì–»ëŠ”ë‹¤.
    
    $$F_{Tfusion}^{i+1} = \text{Fuse}$$
    
2. **Cosine Similarity ê³„ì‚°**
    
    Teacherì˜ higher-level feature $F_T^{i+1}$ê³¼ Studentì˜ ëŒ€ì‘ feature $F_S^{i+1}$ ê°„ cosine similarityë¥¼ ê³„ì‚°í•œë‹¤.
    
    $$Sim = \frac{F_T^{i+1} \cdot F_S^{i+1}}{\|F_T^{i+1}\| \, \|F_S^{i+1}\|}$$
    
    ì—¬ê¸°ì„œ $Sim$ ê°’ì´ ì‘ì„ìˆ˜ë¡ anomalyì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒì„ ì˜ë¯¸í•œë‹¤.
    
3. **Attention ê¸°ë°˜ ì •ë³´ ì£¼ì…**
    
    $Sim$ì€ gating ì—­í• ì„ í•˜ë©°, teacher encoderì—ì„œ ì „ë‹¬ë˜ëŠ” fused featureì˜ ë¹„ìœ¨ì„ ì¡°ì ˆí•œë‹¤. ì´ë¥¼ í†µí•´ anomaly ì˜ì—­ì—ì„œì˜ ë¶ˆí•„ìš”í•œ ì •ë³´ëŠ” ì–µì œë˜ê³ , ì •ìƒ detailë§Œ ì£¼ì…ëœë‹¤. ê²°ê³¼ì ìœ¼ë¡œ detail-enriched feature $F_{SSA}^{i+1}$ë¥¼ ì–»ëŠ”ë‹¤.
    
    $$F_{SSA}^{i+1} = Sim \otimes F_{Tfusion}^{i+1}$$
    
    ($\otimes$ëŠ” element-wise multiplicationì„ ì˜ë¯¸í•œë‹¤.)
    
4. **Decoder ì…ë ¥ êµ¬ì„±**
    
    Student decoderì˜ ê¸°ì¡´ feature $F_S^{i+1}$ì™€ detail-enriched feature $F_{SSA}^{i+1}$ë¥¼ concatí•˜ì—¬ ìµœì¢…ì ìœ¼ë¡œ decoder block $S_i$ì— ì „ë‹¬í•œë‹¤.
    
    $$F_S^i = S_i([F_S^{i+1}, F_{SSA}^{i+1}])$$
    

ì´ ê³¼ì •ì„ í†µí•´ $S_i$ëŠ” ë³´ë‹¤ í’ë¶€í•˜ë©´ì„œë„ anomaly-free detailì´ ì£¼ì…ëœ featureë¥¼ ì…ë ¥ë°›ì•„ ì •ìƒ ì˜ì—­ì€ ì •ë°€í•˜ê²Œ ë³µì›í•˜ê³ , anomaly ì˜ì—­ì€ ë¶ˆì¼ì¹˜í•˜ë„ë¡(normalí•´ì§€ë„ë¡) reconstructí•œë‹¤.

---

### Inference ë‹¨ê³„

![inference.png](/static/images/urd/inference.png)

ë§ˆì§€ë§‰ìœ¼ë¡œ URDì˜ inference ê³¼ì •ì„ í™•ì¸í•´ë³´ì. ì¶”ë¡  ì‹œì—ëŠ” í•™ìŠµ ê³¼ì •ì—ì„œ ì‚¬ìš©ëœ expert network $E$ê°€ ì œê±°ë˜ë©°, ì´ëŠ” ì œì•ˆí•˜ëŠ” ë°©ë²•ì´ **ì¶”ê°€ì ì¸ ì €ì¥ ë¹„ìš©ì´ë‚˜ ì—°ì‚°ëŸ‰ì„ ì¦ê°€ì‹œí‚¤ì§€ ì•ŠìŒ**ì„ ì˜ë¯¸í•œë‹¤.

- **Anomaly Localization**
    
    Localizationì€ RDì™€ ë™ì¼í•˜ê²Œ ì§„í–‰ëœë‹¤. Teacher $T$ì™€ Student $S$ì˜ ì„¸ ê°œ layer feature ê°„ cosine distance mapì„ ê³„ì‚°í•˜ê³ , ì´ë¥¼ ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°ë¡œ upsamplingí•œ ë’¤ í•©ì‚°í•˜ì—¬ ìµœì¢… score mapì„ ì–»ëŠ”ë‹¤.
    
    $$ScoreMap = \sum_{i=1}^3 \Big( 1 - \frac{F_T^i \cdot F_S^i}{\|F_T^i\| \, \|F_S^i\|} \Big)$$
    
- **Anomaly Detection**
    
    ì´ë¯¸ì§€ ë‹¨ìœ„ anomaly scoreëŠ” score mapì˜ ìµœëŒ€ê°’ìœ¼ë¡œ ì •ì˜ëœë‹¤.
    
    $$Score(I) = \max(ScoreMap(I))$$
    

ì´ë¥¼ í†µí•´ pixel-level anomaly localizationê³¼ image-level anomaly detectionì´ ë™ì‹œì— ê°€ëŠ¥í•˜ë‹¤.

ì´ ëª¨ë¸ì— ëŒ€í•œ ë” ìì„¸í•œ ë‚´ìš©ì€, ë³¸ ë…¼ë¬¸ì„ ì°¸ê³ í•˜ë©´ ëœë‹¤ ! :  
[ğŸ“„ Read the paper on arXiv](https://arxiv.org/abs/2412.07579)