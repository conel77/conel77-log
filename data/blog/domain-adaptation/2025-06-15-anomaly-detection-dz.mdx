---
title: "Anomaly Detection with Domain Adaptation"
date: "2025-06-15"
tags: ['anomaly detection', 'domain adaptation', 'semi-supervised', 'IRAD']
draft: false
summary: "Invariant Representation Anomaly Detection(IRAD)을 통한 limited target 데이터 환경에서 anomaly detection을 진행하는 논문 리뷰"
---

# Anomaly Detection with Domain Adaptation

Semi-supervised anomaly detection 문제는 target 도메인에서 라벨링된 데이터가 제한적인 상황에서 정상과 비정상 데이터를 분류해야 한다는 점에서 어려움이 크다.  
특히, source 도메인에서는 정상(normal) 데이터만 사용할 수 있고, target 도메인에서도 일부 정상 데이터만 활용 가능한 상황에서 anomaly를 탐지해야 한다는 점에서, domain adaptation 기반의 접근이 필요하다.

이러한 문제 설정 하에서 본 논문은 **IRAD(Invariant Representation Anomaly Detection)** 구조를 제안하며, shared encoder와 private encoder를 결합한 adversarial training 구조를 통해 feature를 나누고자 하였다.

---

# Overall Method

이 구조는 다른 semi-supervised 방식과 동일하게 feature extraction 과정 중 domain adaptation을 결합하여 target 도메인의 anomaly detection 성능을 향상시키는 것이 목표.  
Source data는 ImageNet으로 pre-trained된 ResNet-50을 통해 feature를 추출하며, normal 데이터만 사용된다.  

Target 도메인은 normal, abnormal 데이터를 모두 포함하되, 학습 시에는 normal 데이터만 활용하며, 이 역시 ResNet 기반 shared encoder를 통해 feature를 추출하게 된다.  
이러한 shared feature와 source domain 에 특징된 feature를 함께 활용하여 generator를 통해서 target-like 이미지를 생성하고, 이를 통해 최종적으로 anomaly detection을 수행한다.

Discriminator는 사전학습되지 않은 ResNet-18을 기반으로 이루어져 있다.

---

# Problem Statements

본 논문이 다루는 문제는 다음과 같다:

- **Settings**: source 도메인과 제한된 target 도메인 데이터가 주어짐
- **Limitations**: 학습 시에는 source와 target의 normal data만 사용 가능함
- **Test Env**: test set은 normal과 abnormal이 혼합됨
- **Metric**: AUROC을 사용하여 anomaly detection 성능을 평가함

---

# Method
## Shared + Private Encoder

기존의 domain adaptation 연구에서는 도메인이 달라져도 변하지 않는 **공통된 feature (domain-invariant feature)** 를 추출하는 방식이 일반적이다.  
IRAD는 이러한 기존 방식에 기반을 두면서도, **공통 feature와 domain-specific feature를 명확히 분리**하는 데 중점을 둔다.

이를 위해 shared encoder와 더불어 **private encoder**를 도입하였으며, 특히 source 도메인에 대해 특정된 정보를 뽑아내기 위해 adversarial training 구조를 사용하였다.

---

## Generator Training

Generator에서는 다음과 같은 방식으로 학습이 진행된다:

1. **공통 feature + source-specific feature (from source)** → 하나의 이미지 생성
2. **공통 feature (from target) + source-specific feature** → 또 하나의 이미지 생성  
   이 둘은 discriminator를 통해 **같은 이미지**처럼 보이도록 유도된다.
3. **random vector + shared feature (from source)** → 추가로 하나 생성하여, private encoder가 과도하게 영향력을 갖지 않도록 제어한다.

Discriminator는 이 세 가지 이미지와 실제 source 이미지를 구분하도록 학습되며, 이 과정을 통해 **target domain에 align된 feature 공간을 구축**할 수 있게 된다.

---

## Cycle Consistency Loss

GAN 기반 학습에서는 high-dimensional 공간에서 mode collapse 혹은 비현실적인 결과가 발생하는 문제가 있다. 이를 해결하기 위해 본 논문에서는 **Cycle Consistency Loss**를 추가로 도입하였다.

- **진짜 source 이미지 ↔ 생성된 source 이미지 간 차이**  
- **진짜 source 이미지 ↔ target feature로부터 생성된 source 이미지 간 차이**

이러한 두 종류의 consistency loss를 통해 학습의 안정성을 확보하고자 하였다.

---

# Feature 분리 최적화를 위한 추가 Loss

shared encoder와 private encoder가 **서로 다른 특징**을 추출해야 하기 때문에, 각 encoder의 역할을 명확히 분리하는 목적의 추가적인 loss term을 도입하였다.

###  Disentanglement Loss

```math
l_{dis} = ||E_{sh}(x_{src})^T E_{pv}(x_{src})||
```

### Similarity Loss

```math
l_{sim} = - \left\| E_{sh}(x_{src})^T E_{sh}(x_{tgt}) \right\|
```

Source와 target의 shared feature가 유사한 방향을 갖도록 유도하기 위해 두 벡터의 내적을 최대화하는 방향으로 학습된다.이는 target 데이터가 적은 상황에서도 공통 feature space를 효과적으로 구축하기 위한 핵심 요소이다.

